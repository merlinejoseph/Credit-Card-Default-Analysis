---
title: "Credit Card Default Analysis"
date: "24/11/2020"
output: 
  pdf_document: 
    toc: yes
    fig_width: 4
    fig_height: 3.5
    fig_caption: yes
---

```{r setup, include=FALSE}
pacman::p_load(caret, corrplot, MASS, tidyverse, ggthemes,
               scales, ggplot2, gtools, Hmisc, devtools, randomForest, 
               PerformanceAnalytics,DMwR, ROSE,rpart, rpart.plot,gbm,adabag)
knitr::opts_chunk$set(echo = TRUE)
```

# Executive Summary

Credit card default risk is one of the major risks faced by any credit card company. This can create a huge loss for the company. The companies nowadays, use data to find the potential defaulters. This is where predictive analytics comes into picture.  
A good predictive model would help companies identify which clients are likely to default. This would provide them the opportunity to address and minimize the potential losses. 

In our project, we will be doing the hypothesis testing for the following claims to identify possible defaulters:  

1. **NULL Hypothesis** : *Clients are likely to default if the Balance-to-limit Ratio = 2.*   

Analysis: We are expecting to see higher likelihood of default in payment when the Balance-to-limit Ratio is over 2:1.

2. **NULL Hypothesis** : *True difference in means of ages of non defaulters and defaulters is greater than or equal to 0*    

Analysis: We are expecting older clients to default more than the younger clients.

3. **NULL Hypothesis** : *The Default Ratio among males is less than or equal to that among females.*   

Analysis: We are expecting Default ratio among males to be higher than that among females.  

Additionally, we analyzed the patterns that lead to a default in credit card payment. We have used the following models to classify various credit card users in our paper : 

* *Logistic Regression*
* *Random Forest Classifier*
* *Boosting Classifier*   

we have utilized a variety of techniques to reduce the number of variables used in the above models, including **Step AIC**, **RegSubsets** and **Decision Trees** using Rpart.

The class of importance in the Dataset is **Default = '1'**. But there are very less proportion of defaulters as compared to non-defaulters in the dataset.This leads to a very low sensitivity in the models built. We have attempted to solve this by oversampling the training set with **SMOTE (Synthetic Minority Oversampling Technique)** bringing the number of defaulters in the training set to be higher compared to number of non-Defaulters.

Finally, we compare different models based on their sensitivity and finalize two models optimizing  their Sensitivity,Specificity and Accuracy. We would recommend *Logistic Regression using variables from Decision Tree* for better sensitivity and *Boosting Classifier* for a balanced model with similar values of sensitivity, specificity and accuracy.    


\newpage
# A.   Introduction

Credit card default happens when we fail to commit to your credit card payments. Default is a serious credit card offense that can not only affect our standing with the card issuer company, but also with all other companies in general.When we accept a credit card, we agree to certain terms and conditions and we are liable and bound to commit to it.Generally, in the US, If we miss the minimum payment six months in a row, our credit card will be in default. The credit card issuer will likely close the account and report the issue to the credit bureaus.   

In this paper, the information of clients such as balances, payments and defaults were collected. Analyzing this data helps the credit card company in : 

- *Understanding the factors that lead to defaults in payment.*    
- *Providing a signal of a possible default so that an early intervention can be done.*    
- *Improving policies to manage risks and losses.*    
- *Help the clients to better manage their finances to avoid defaults.*    

If a person defaults and fails to pay the credit card bill, the issuer company can take a legal action against that person and if the person has no possible way to pay the debt, he/she will have to declare bankruptcy. Also the defaults, has a very bad impact to that person's credit score preventing him/her to get a new credit card in the future. All this can cause a huge loss to the credit card company and in this paper, our main objective is to create a model that can correctly classify the possible defaulters in advance so as to warn the company and potentially help them save a huge amount of money.    

# B.   Data Description

The credit card default dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. There are 25 variables and 30,000 records. There are no missing values. Variables include amount of given credit,  gender, marital status, age, education, monthly repayment status, monthly bill statement, monthly bill payments. The response/ outcome variable is whether there was a default in payment- **Yes= 1, No= 0**.   

Here PAY_0, PAY_2, PAY_3, PAY_4, PAY_5, PAY_6 shows the repayment status in September 2005, August 2005, July 2005 and so on. It is a categorical variable with values -1 signifying pay duly, 1 = payment delay for one month, 2 = payment delay for two months and so on.   

All payment amounts in this dataset are in NT Dollars ( New Taiwan Dollar).   

```{r Data Description, echo=FALSE, message=FALSE, warning=FALSE}
credit<- read.csv("UCI_Credit_Card.csv")
str(credit)

```

# C.   Data Preprocessing   

Since there are no missing values, we took the dataset in its original form. A few names of the variables were changed to make them more reader-friendly. Years of education 0, 5 and 6, have been binned together as "other" since they represent a small percentage of the dataset.Since we have around 30,000 variables, the normality of the dataset can be assumed. Also we have changed the name of PAY_0 to PAY_1 for easier naming and identification purpose. The values above 3 in PAY_1 to PAY_6 has been assumed to be take the value 4 because there are very less values above 3 in these categories. The variables SEX, EDUCATION, MARRIAGE, PAY_1, PAY_2, PAY_3, PAY_4, PAY_5, PAY_6 are categorical variables and they are coverted into factors.   


```{r Preprocessing, message=FALSE, warning=FALSE, include=FALSE}
credit <- credit[-1]
credit <- credit %>% rename(Default = default.payment.next.month) 
credit <- credit %>% rename(PAY_1 = PAY_0)  
#to keep it consistent with variables "BILL_AMT1" and "PAY_AMT1"

#grouping 0,5,6 under 4 and interpreted as "others"
credit$EDUCATION[credit$EDUCATION== 0]  <- 4 
credit$EDUCATION[credit$EDUCATION== 5]  <- 4 
credit$EDUCATION[credit$EDUCATION== 6]  <- 4 

credit$PAY_1[credit$PAY_1>3]  <- 4 
credit$PAY_2[credit$PAY_2>3]  <- 4 
credit$PAY_3[credit$PAY_3>3]  <- 4 
credit$PAY_4[credit$PAY_4>3]  <- 4 
credit$PAY_5[credit$PAY_5>3]  <- 4 
credit$PAY_6[credit$PAY_6>3]  <- 4 

# there is only 2 PAY_4 values with 1. Removing it as a possible outlier or mistake. 
credit <- credit[credit$PAY_4 != 1,]

factor_vars <- c('SEX','EDUCATION','MARRIAGE','PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')
credit[factor_vars] <- lapply(credit[factor_vars], function(x) as.factor(x))

credit1= credit  #duplicate
```


Having a look at correlation of DEFAULT with other variables.

1.We can see BILL_AMT1 ~ BILL_AMT5 having high correlation to each other , so can create a multicollinearity problem while model building.

2.We have the highest correlation with LIMIT_BAl of -0.2 , the sign is negative showing higher the LIMIT_BAL lower the tendency to DEFAULT.


```{r Correlation Plot, echo=FALSE, fig.cap="From the correlation matrix plot, we can deduce that bill amounts are highly correlated with each other with a correlation value of 0.9 and the least correlated would be PAY_3, PAY_2, PAY_1, PAY_5, PAY_4, PAY_6 with respect to LIMIT_BAL.", message=FALSE, warning=FALSE}
#Plotting a correlation plot
library(ggcorrplot)
corr_df <- credit1[, -c(2,3,4,6,7,8,9,10,11)]
corr <-  round(cor(corr_df),1)
ggcorrplot(corr, hc.order=TRUE, type = "lower",lab=TRUE, 
           outline.color = "white", ggtheme = ggplot2::theme_gray,
           colors=c("#6D9EC1", "white", "#E46726"), tl.cex = 7, lab_size = 2)
```

Another look at the correlation of DEFAULT with other variables after removing the BILL_AMT2 ~ BILL_AMT6.

```{r Correlation plot2, echo=FALSE, fig.cap="correlation plot additionally removing variables 13,14,15,16 and 17", message=FALSE, warning=FALSE}
corr_df <- credit1[, -c(2,3,4,6,7,8,9,10,11,13,14,15,16,17)] 
corr <-  round(cor(corr_df),1)
ggcorrplot(corr, hc.order=TRUE,lab=TRUE,type = "lower",
           outline.color = "white", ggtheme = ggplot2::theme_gray,
           colors=c("#6D9EC1", "white", "#E46726"), tl.cex = 7, lab_size = 2)
```
Thus we remove the highly correlated variables so as to make our algorithms faster and more efficient.

```{r removing highly correlated variables, message=FALSE, warning=FALSE, include=FALSE}
credit1 <- credit1[,-c(13,14,15,16,17)]
```

# D.    Exploratory Data Analysis

We first visualize the Distribution's of the variables in the intial Dataset retrieved from UCI Repository.

1. We can see that the LIMIT_BAL is positively skewed.
2. BILL_AMT1 has a better distribution but a slight skew could be seen the graph.
3. The distribution of AGE is also positively skewed in the Dataset.

```{r Histogram of LIMIT_BAL, message=FALSE, warning=FALSE, echo=FALSE}
#Plotting Histograms
par(mfrow=c(2,2))
hist(credit$LIMIT_BAL, breaks = 20)
hist(credit$BILL_AMT1, breaks = 20)
hist(credit$AGE, breaks = 20)
```


Visualize the relationship between DEFAULT and SEX.

It could be observed from the graph that Male have a higher ratio to Default then Female.

```{r Relationship between DEFAULT~SEX, message=FALSE, warning=FALSE, echo=FALSE}
#Relationship between variables "Default" and "SEX"
credit4 <- credit
credit4$SEX <- factor(credit4$SEX, labels = c("Male","Female"))
summarized<-credit4 %>% group_by(SEX, Default) %>% summarise(Freq=n()) 
summarized$Default <- as.logical(as.integer(summarized$Default))
ggplot(summarized, aes(x= Default,y = Freq)) +geom_col()+ 
  facet_wrap(~SEX)+ theme_bw()
```



It could be seen that the median value of LIMIT_BAL for Graduate School Education is the highest. Median values for University and High School, have relatively reduced. It signifies that individuals having attended Graduate program receive higher Limit to there Credit card from banks.
```{r Boxplot of Credit Limit ~ Education, message=FALSE, warning=FALSE, echo=FALSE}
# Boxplots of amount of credit limit by education
credit4$EDUCATION <- factor(credit4$EDUCATION, 
                      labels = c("Graduate School","University","High School",
                                                          "Others"))
qplot(EDUCATION, LIMIT_BAL, data=credit4, geom=c("boxplot"),
      fill=EDUCATION, main="Limit Amount by Education ",
      xlab="", ylab="Amount of credit given")
```



Visualizing DEFAULT with respect to Education.

Though we see a Default count of High School lower than Graduate School and University. But in overall ratio High School individuals have a higher ratio to Default.

```{r message=FALSE, warning=FALSE, echo=FALSE}
#Bar graph of education with respect to Default in Payment
DefaultPayment = as.factor(credit$Default)
ggplot(credit4, aes(x = EDUCATION, fill = DefaultPayment)) + 
  geom_bar() + labs(x = 'Education') + theme_excel()
```



Visualize DEFAULT against AGE.

We can see that most of the individuals age lie between 20 to 40. The youngest client age is 21 and oldest is 79.
It could be also observed that the default ratio remains constant for the distribution.

```{r ar plot of Age with respect to Default, echo=FALSE, message=FALSE, warning=FALSE}
#Bar plot of Age with respect to Default in payment
ggplot(credit4, aes(x = AGE, fill = DefaultPayment)) +
  geom_bar() +
  labs(x = 'Age') +
  theme_excel()
```


Visualize Age versus Credit Balance Amount.

It could be seen that the Limit for Credit initially increases from 20 to 35, then remains constant till 60 then withers off.

```{r BAL_LIMIT~AGE, echo=FALSE, warning=FALSE, message=FALSE}
#Scatterplot showing how balance limit changes with age
scatter <- ggplot(credit, aes(x = AGE, y = LIMIT_BAL))
scatter + geom_count(col="blue", show.legend=F) +
  labs( subtitle="Age Vs Credit Balance Amount")
```


We have split the entire dataset into a training data and a validation data. The split is done with 80% of the data belonging to the training data and the remainnig 20% in the validation data. We can see that the number of 1's , that is the number of defaulter's in the dataset is very less compared to 0's, that is non defaulters. Thus, we will not be create a good classification model using this training data set. The sample here is undersampled and the class of interest 1, here is a minority. Inorder to rectify this problem, we have used an oversampling technique called **SMOTE** to oversample the minority, so as to almost make the proportion of defaulters and non defaulter's almost comparable. SMOTE uses K means and other algorithm to create the artificial samples. So we will be able to create a model with much better classification capability when we use the oversampling with smote.   


```{r Partition Training and validation, echo=FALSE, message=FALSE, warning=FALSE}

#Setting the seed value and sample partitioning
set.seed(123)
smp_size <- floor(0.80 * nrow(credit))
#credit1$balanceRatio <- credit$BalanceRatio
train_index <-  sample(seq_len(nrow(credit1)), size=smp_size)
train_df <-  credit1[train_index,]
valid_df <-  credit1[-train_index,]
dim(train_df)
dim(valid_df)
```

Here we can see that the difference in proportion of the defaulter's and non defaulter's in the training dataset.   

```{r SMOTE, echo=FALSE, message=FALSE, warning=FALSE}
train_df_smote <- train_df
train_df_smote$Default <- as.factor(train_df_smote$Default)
train_df_smote <- SMOTE(Default ~ ., train_df_smote,perc.over = 200,perc.under = 100)
train_df_smote$Default <- as.integer(as.character(train_df_smote$Default))
table(train_df_smote$Default)
```

Here we can see that after applying SMOTE transformation, the proportion of the defaulter's and non defaulter's are almost equal and comparable.   


# E.   Empirical Analysis   


## Hypothesis Testing


```{r Balance ratio, message=FALSE, warning=FALSE, include=FALSE}
credit$Balance <- credit$PAY_AMT1+ credit$PAY_AMT2+
  credit$PAY_AMT3+ credit$PAY_AMT4+ credit$PAY_AMT5+  
  credit$PAY_AMT6 -(credit$BILL_AMT1+credit$BILL_AMT2+  
                      credit$BILL_AMT3+ credit$BILL_AMT4+  
                      credit$BILL_AMT5+ credit$BILL_AMT6)
credit$BalanceRatio <- -credit$Balance/credit$LIMIT_BAL
anova(lm(credit$BalanceRatio~ credit$Default))

defaulter_BalanceRatio <- credit[credit$Default == 1,"BalanceRatio"]
non_defaulter_BalanceRatio <- credit[credit$Default == 0, "BalanceRatio"]

#T TEST
test1 <- t.test(defaulter_BalanceRatio, mu=2, alternative = "g")
#true mean >2
test2 <- t.test(non_defaulter_BalanceRatio, mu=2, alternative = "l")
#true mean <2

```

### First Hypothesis

NuLL Hypothesis : *Clients are likely to default if the Balance-to-limit Ratio < = 2.*    
Alternate Hypothesis : *Clients are less likely to default if the balance-to-limit ratio is greater than 2.*   


```{r Hypothesis 1, echo=FALSE, message=FALSE, warning=FALSE}
#T TEST
test1 <- t.test(defaulter_BalanceRatio, mu=2, alternative = "g")
test1
test2 <- t.test(non_defaulter_BalanceRatio, mu=2, alternative = "l")
test2
```

Here we can clearly see that for **defaulters**, the mean value of the balance to limit ratio is greater than 2 and p value < alpha, alpha being 0.05 (95% Confidence). Here we can reject the NULL Hypothesis and accept the Alternative Hypothesis. Thus the mean balance to limit ratio for defaulters are above 2. For **Non Defaulters**, the mean value of the balance to limit ratio is less than 2. Here pvalue < alpha(0.05) and thus we can reject the NULL Hypothesis and accept alternative Hypothesis. Thus the mean balance to limit ratio for non defaulters are less than 2.    

### Second Hypothesis  

NULL Hypothesis : *true difference in means of ages of non defaulters and defaulters is greater than or equal to 0.*   
Alternative Hypothesis : *true difference in means of ages of non defaulters and defaulters is less than 0.*   

```{r Second Hypothesis, echo=FALSE, message=FALSE, warning=FALSE}
testAge<-t.test(credit$AGE~ credit$Default, alternative= "l")
testAge
#defaulter age>non defaulter. diff= 0.2
```

Here we see that from the T Test, the mean age of non defaulters is less than that of the defaulters. Here the pvlaue < alpha(0.05) at 95% Confidence level, Thus we can reject the NULL Hypothesis and accept Alternative Hypothesis. Thus the mean age of people who are likely to default are higher than those who are less likely to default.   

### Third Hypothesis

NULL Hypothesis : *The Default Ratio among males is less than or equal to that among females.*    
Alternative Hypothesis : *The Default Ratio among males is greater than that of females*   

```{r Third Hypothesis, echo=FALSE, message=FALSE, warning=FALSE}
#prop.test(x=c(2872, 3763), n=c(11886,18112))
#True Difference is not 0. Default Prop male>female
prop.test(x=c(2872, 3763), n=c(11886,18112),alternative = "g")
#Proportion of default for males is greater than proportion of default for females

```
Here we use the Proportion T Test to check the equality of proportions. We can see from the above result that, the mean proportion of the defaulters in male is greater than that of the female. Here p value < alpha(0.05) and thus we reject the NULL hypothesis and accept the Alternative Hypothesis. Thus we can say that the true mean of the proportion of defaulters among males is greater than that of female at 95% Confidence.   

## Logistic Regression   

### Simple Logistic Regression

First, we run the simple logistic regression to all the variables in the oversampled training dataset and train the model and then predict with the validation dataset.   

```{r Simple Logistic Regression, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
simple_logistic <- glm(Default ~ ., data = train_df_smote, family = "binomial")
summary(simple_logistic)
simple_logistic.pred <- predict(simple_logistic, valid_df,type = 'response')
#Considering Probability threshold as 0.45
simple_logistic.result <- ifelse(simple_logistic.pred > 0.45, 1, 0)
simple_logistic.result <- factor(simple_logistic.result)

confusionMatrix(simple_logistic.result, as.factor(valid_df$Default),positive = "1")

```

From the above result we can see that when the probability threshold is 0.45, the simple logistic regression model is predicting with a sensitivity of 0.73, specificity of 0.64, accuracy of 0.66. This is overall a good model. If we select a lower threshold we can get an improved sensitivity, but the specificity gets bad. When the threshold is 0.45, there is an good trade off between the sensitivity and specificity and thus we have decided to use this probability value.   

### StepAIC + Logistic   

Here we are running the StepAIC to select the best subset of variables that can predit the classification most appropriately. Then we run the logistic regression on the best subset.   


```{r Step AIC+Logistic, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
#Running a stepAIC model with Logistic regression to reduce the number of variables based on accuracy
logit <- glm( Default ~ ., data = train_df_smote, family = "binomial")
stepLogit <- stepAIC(logit,direction = "both")
stepLogit.pred <- predict(stepLogit, valid_df, type = "response")
valid_df$Default= as.factor(valid_df$Default)

predicted.classes <- ifelse(stepLogit.pred > 0.45, 1, 0)
predicted1.classes <- factor(predicted.classes)
confusionMatrix(predicted1.classes, valid_df$Default, positive = '1')
```


Here from this model we get a sensitivity of 0.73, specificity of 0.64, overall accuracy of 0.66. This is also a good model.   


### Regsubsets

Here we run the regsubsets using backward method from the leaps package to select the best model with the best predictor variables and use that variables to perform the logistic regression to check if we got any considerable improvement from the simple logistic regression.   


```{r Reg Subsets, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
library(leaps)
set.seed(123)
regsub_smote <- regsubsets(Default~., data =  train_df_smote, method = "backward")
summary_smote <- summary(regsub_smote)
summary_smote$adjr2
summary_smote$bic
## LIMIT_BAL + PAY_1 + +PAY_2 + PAY_3 +PAY_4

```

Here from the adjusted Rsquare and bic value, we choose the model 8 as the best model and it has LIMIT_BAL, PAY_1, PAY_2, PAY_3, PAY_4 as the predictors.

```{r Logistic regression with parameters from RegSubsets smote, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
logistic_smote <- glm(Default ~ LIMIT_BAL+PAY_1+PAY_2+PAY_3+PAY_4, data = train_df_smote, family = 'binomial')
summary(logistic_smote)
## LIMIT_BAL + PAY_1 + PAY_3 + PAY_4
logistic_smote.pred <- predict(logistic_smote, valid_df,type = 'response')
logistic_smote.result <- ifelse(logistic_smote.pred > 0.45, 1, 0)
logistic_smote.result <- factor(logistic_smote.result)

confusionMatrix(logistic_smote.result, as.factor(valid_df$Default), positive = "1")
```

Here in this model, we are getting at probability threshold equal to 0.45, we get a sensitivity of 0.71 and specificity of 0.63 with overall acuuracy of 0.65.   


When we use the forward method for predictor selection, we add PAY_6 also to the previous model.   

```{r echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
library(leaps)
regsub_smote1 <- regsubsets(Default~., data =  train_df_smote, method = "forward")
summary_smote1 <- summary(regsub_smote1)
summary_smote1$adjr2
summary_smote1$bic
## LIMIT_BAL + PAY_1 + +PAY_2 + PAY_3 +PAY_4 +PAY_6
```

Here from the adjusted Rsquare and bic value, we choose the model 8 as the best model and it has LIMIT_BAL, PAY_1, PAY_2, PAY_3, PAY_4,PAY_6 as the predictors.   

```{r Logistic regression with parameters from RegSubsets - forward, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
logistic_smote2 <- glm(Default ~ LIMIT_BAL+PAY_1+PAY_2+PAY_3+PAY_4+PAY_6, data = train_df_smote, family = 'binomial')
#summary(logistic_smote2)
## LIMIT_BAL + PAY_1 + PAY_3 + PAY_4 +PAY_5 +PAY_6
logistic_smote2.pred <- predict(logistic_smote2, valid_df,type = 'response')
logistic_smote2.result <- ifelse(logistic_smote2.pred > 0.45, 1, 0)
logistic_smote2.result <- factor(logistic_smote2.result)

  confusionMatrix(logistic_smote2.result, as.factor(valid_df$Default), positive = "1")
```
After performing logistic regression from the best model obtained from the forward subset selection model, we get sensitivity of 0.72, specificity of 0.62, overall accuracy of 0.64.   

## Decision Tree  


```{r Decision Tree + Logistic regression, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
set.seed(123)

rpart.credit <- rpart(as.factor(Default)~ ., data =train_df_smote, cp = .01)
rpart.plot(rpart.credit)
``` 

```{r logistic decision tree variables, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
#logistic regression with decision tree variables
Model1 <- glm(as.factor(Default) ~ PAY_1+PAY_2 + PAY_3 + PAY_4 +BILL_AMT1+ PAY_AMT1+PAY_AMT2, data = train_df_smote, family = "binomial")

Model1.pred <- predict(Model1, valid_df, type = "response")
#df <- data.frame(actual = valid_df$Default, prediction = logistic_smote.pred)
Model1.result <- ifelse(Model1.pred > 0.45, 1, 0)
Model1.result <- factor(Model1.result)
confusionMatrix(Model1.result, as.factor(valid_df$Default), positive = "1")
```

Here from the above result, we can see that our model with the best predictors obtained from the decision tree, we get an sensitivity of 0.74, specificity of 0.62 and an accuracy of 0.65.   


## Random Forest Classifier

On running the Random Forest Classifier with 1000 number of trees and number of predictors at each node as 5, we obtain the following results :


```{r Random Forest using cross validation and variables from Regsubsets, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
#random forest on the reduced model 
rnf1 <-  randomForest(as.factor(Default) ~ .,ntree=1000 ,mtry = 5, data = 
                        train_df_smote, cutoff =c(0.55,0.45))
rnf1
rnf1_model.pred <- predict(rnf1, valid_df)
#valid_df$Default= factor(valid_df$Default)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

confusionMatrix(rnf1_model.pred, as.factor(valid_df$Default), positive="1")
```
By running the random forest classifier with a cutoff value of 0.45, we get a sensitivity of 0.64, specificity of 0.72 and overall accuracy of 0.71.   

## Boosting Classifiers

```{r Boosting, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
train_df_smote$Default <- factor(train_df_smote$Default)
boost <- boosting(Default~ .,data = train_df_smote)
pred <- predict(boost, valid_df)
boost2 <- ifelse(pred$prob[ , 2] > 0.45, 1, 0)
confusionMatrix(as.factor(boost2), as.factor(valid_df$Default),positive = '1')
```
From the classification using boosting, we are getting a sensitivity of 0.69, specificity of 0.67 and accuracy of 0.67.    

&nbsp;
The results obtained from the above algorithms and methods have been organized in the folowing tables : 

* *Table 1 shows the sensitivity, specificity and accuracy when the probability cutoff is default*

```{r echo=FALSE}
Algorithms <- c("Simple Logistic Regression","Step AIC + Logistic Regression", "Backward Selection + Logistic Regression", "Forward Selection + Logistic Regression", "Decision Tree + Logistic Regression", "Random Forest", "Boosting (adaboost)")
df <- data.frame(Algorithms)
df$Sensitivity <- c(0.6773,0.6780,0.6555,0.6594,0.6517,0.6005,0.6129)
df$Specificity <- c(0.7043,0.7039,0.7039,0.6999,0.7217,0.7820,0.7707)
df$Accuracy <- c(0.6985,0.6983,0.6935,0.6912,0.7067,0.743,0.7368)
knitr::kable(df, caption = "Performance when probability cutoff is 0.5")   

```

* *Table 2 shows the sensitivity, specificity and accuracy when the probability cutoff is 0.45*


```{r echo=FALSE}
df1 <- data.frame(Algorithms)
df1$Sensitivity <- c(0.7269,0.7269,0.7075,0.7184,0.7362,0.6393,0.6912)
df1$Specificity <- c(0.6355,0.6357,0.6302,0.6236,0.6228,0.7277,0.6659)
df1$Accuracy <- c(0.6552,0.6553,0.6468,0.644,0.6472,0.7087,0.6713)
knitr::kable(df1, caption = "Performance when probability threshold 0.45")
```


# Conclusion    



\newpage
# Appendix   

```{r Appendix, eval=FALSE}
# Loading the Package
pacman::p_load(caret, corrplot, MASS, tidyverse, ggthemes,
               scales, ggplot2, gtools, Hmisc, devtools, randomForest, 
               PerformanceAnalytics,DMwR, ROSE,rpart, rpart.plot) 

#Preprocessing
credit<- read.csv("UCI_Credit_Card.csv")
str(credit)
credit <- credit[-1]
credit <- credit %>% rename(Default = default.payment.next.month) 
credit <- credit %>% rename(PAY_1 = PAY_0)  
#to keep it consistent with variables "BILL_AMT1" and "PAY_AMT1"

#grouping 0,5,6 under 4 and interpreted as "others"
credit$EDUCATION[credit$EDUCATION== 0]  <- 4 
credit$EDUCATION[credit$EDUCATION== 5]  <- 4 
credit$EDUCATION[credit$EDUCATION== 6]  <- 4 

credit$PAY_1[credit$PAY_1>3]  <- 3 
credit$PAY_2[credit$PAY_2>3]  <- 3 
credit$PAY_3[credit$PAY_3>3]  <- 3 
credit$PAY_4[credit$PAY_4>3]  <- 3 
credit$PAY_5[credit$PAY_5>3]  <- 3 
credit$PAY_6[credit$PAY_6>3]  <- 3 

# there is only 2 PAY_4 values with 1. Removing it as a possible outlier/mistake. 
credit <- credit[credit$PAY_4 != 1,]

factor_vars <- 
c('SEX','EDUCATION','MARRIAGE','PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')
credit[factor_vars] <- lapply(credit[factor_vars], function(x) as.factor(x))

credit1= credit  #duplicate

#Plotting Histograms
hist(credit$LIMIT_BAL, breaks = 20 )
hist(credit$BILL_AMT1, breaks = 20 )
hist(credit$AGE, breaks = 20 )
hist(credit$PAY_AMT1, breaks = 20 )

#Relationship between variables "Default" and "SEX"
credit4 <- credit
credit4$SEX <- factor(credit4$SEX, labels = c("Male","Female"))
summarized<-credit4 %>% group_by(SEX, Default) %>% summarise(Freq=n()) 
summarized$Default <- as.logical(as.integer(summarized$Default))
summarized
ggplot(summarized, aes(x= Default,y = Freq)) +geom_col()+ 
  facet_wrap(~SEX)+ theme_classic()

# Boxplots of amount of credit limit by education
credit4$EDUCATION <- factor(credit4$EDUCATION, 
                      labels = c("Graduate School","University","High School",
                                                          "Others"))
qplot(EDUCATION, LIMIT_BAL, data=credit4, geom=c("boxplot"),
      fill=EDUCATION, main="Limit Amount by Education ",
      xlab="", ylab="Amount of credit given")

#Bar graph of education with respect to Default in Payment
DefaultPayment = as.factor(credit$Default)
ggplot(credit, aes(x = EDUCATION, fill = DefaultPayment)) + 
  geom_bar() + labs(x = 'Education') + theme_excel()

#Bar plot of Age with respect to Default in payment
ggplot(credit, aes(x = AGE, fill = DefaultPayment)) +
  geom_bar() +
  labs(x = 'Age') +
  theme_excel()

#Scatterplot showing how balance limit changes with age
scatter <- ggplot(credit, aes(x = AGE, y = LIMIT_BAL))
scatter + geom_count(col="blue", show.legend=F) +
  labs( subtitle="Age Vs Credit Balance Amount")


#Balance Ratio found for testing the null hypothesis
credit$Balance <- credit$PAY_AMT1+ credit$PAY_AMT2+
  credit$PAY_AMT3+ credit$PAY_AMT4+ credit$PAY_AMT5+  
  credit$PAY_AMT6 -(credit$BILL_AMT1+credit$BILL_AMT2+  
                      credit$BILL_AMT3+ credit$BILL_AMT4+  
                      credit$BILL_AMT5+ credit$BILL_AMT6)
credit$BalanceRatio <- -credit$Balance/credit$LIMIT_BAL
anova(lm(credit$BalanceRatio~ credit$Default))

defaulter_BalanceRatio <- credit[credit$Default == 1,"BalanceRatio"]
non_defaulter_BalanceRatio <- credit[credit$Default == 0, "BalanceRatio"]

#T TEST
test1 <- t.test(defaulter_BalanceRatio, mu=2, alternative = "g")
#true mean >2
test2 <- t.test(non_defaulter_BalanceRatio, mu=2, alternative = "l")
#true mean <2
test3 <- t.test(defaulter_BalanceRatio, non_defaulter_BalanceRatio)
#reject the null. Means are not equal. X>Y
test4<- t.test(credit$BalanceRatio~ credit$Default)
#Mean balance ratio of defaulters is 0.62 more than that of non-defaulters
testAge<-t.test(credit$AGE~ credit$Default, alternative= "l")
#defaulter age>non defaulter. diff= 0.2
#prop.test(x=c(2872, 3763), n=c(11886,18112))
#True Difference is not 0. Default Prop male>female
prop.test(x=c(2872, 3763), n=c(11886,18112),alternative = "g")
#Proportion of default for males is greater than proportion of default for
#females


#Plotting a correlation plot
library(ggcorrplot)
corr_df <- credit1[, -c(2,3,4,6,7,8,9,10,11)]
corr <-  round(cor(corr_df),1)
ggcorrplot(corr, hc.order=TRUE, type = "lower",lab=TRUE, 
           outline.color = "white", ggtheme = ggplot2::theme_gray,
           colors=c("#6D9EC1", "white", "#E46726"), tl.cex = 7, lab_size = 2)


#correlation plot additionally removing variables 13,14,15,16 and 17
corr_df <- credit1[, -c(2,3,4,6,7,8,9,10,11,13,14,15,16,17)] 
corr <-  round(cor(corr_df),1)
ggcorrplot(corr, hc.order=TRUE,lab=TRUE,type = "lower",
           outline.color = "white", ggtheme = ggplot2::theme_gray,
           colors=c("#6D9EC1", "white", "#E46726"), tl.cex = 7, lab_size = 2)

credit1 <- credit1[,-c(13,14,15,16,17)]


#Setting the seed value and sample partitioning
set.seed(123)
smp_size <- floor(0.80 * nrow(credit))
#credit1$balanceRatio <- credit$BalanceRatio
train_index <-  sample(seq_len(nrow(credit1)), size=smp_size)
train_df <-  credit1[train_index,]
valid_df <-  credit1[-train_index,]
dim(train_df)
dim(valid_df)

#SMOTE
train_df_smote <- train_df
train_df_smote$Default <- as.factor(train_df_smote$Default)
train_df_smote <- SMOTE(Default ~ ., train_df_smote,perc.over = 200,
                        perc.under = 100)
train_df_smote$Default <- as.integer(as.character(train_df_smote$Default))
table(train_df_smote$Default)

#Performing a simple logistic regression model
simple_logistic <- glm(Default ~ ., data = train_df_smote, family = "binomial")
simple_logistic.pred <- predict(simple_logistic, valid_df,type = 'response')
simple_logistic.result <- ifelse(simple_logistic.pred > 0.45, 1, 0)
simple_logistic.result <- factor(simple_logistic.result)
confusionMatrix(simple_logistic.result, as.factor(valid_df$Default),
                positive = "1")


#Running a stepAIC model with Logistic regression to reduce the number of 
#variables based on accuracy
logit <- glm( Default ~ ., data = train_df_smote, family = "binomial")
stepLogit <- stepAIC(logit,direction = "both")
stepLogit.pred <- predict(stepLogit, valid_df, type = "response")
valid_df$Default= as.factor(valid_df$Default)

predicted.classes <- ifelse(stepLogit.pred > 0.45, 1, 0)
predicted1.classes <- factor(predicted.classes)
confusionMatrix(predicted1.classes, valid_df$Default, positive = '1')

#Backward Subset Selection
library(leaps)
set.seed(123)
regsub_smote <- regsubsets(Default~., data =  train_df_smote,
                           method = "backward")
summary_smote <- summary(regsub_smote)
summary_smote$adjr2
summary_smote$bic
## LIMIT_BAL + PAY_1 + +PAY_2 + PAY_3 +PAY_4

set.seed(123)
logistic_smote <- glm(Default ~ LIMIT_BAL+PAY_1+PAY_2+PAY_3+PAY_4,
                      data = train_df_smote, family = 'binomial')
summary(logistic_smote)
## LIMIT_BAL + PAY_1 + PAY_3 + PAY_4
logistic_smote.pred <- predict(logistic_smote, valid_df,type = 'response')
logistic_smote.result <- ifelse(logistic_smote.pred > 0.45, 1, 0)
logistic_smote.result <- factor(logistic_smote.result)

confusionMatrix(logistic_smote.result, as.factor(valid_df$Default),
                positive = "1")


#Forward Subset Selection


set.seed(123)
library(leaps)
regsub_smote1 <- regsubsets(Default~., data =  train_df_smote,
                            method = "forward")
summary_smote1 <- summary(regsub_smote1)
summary_smote1$adjr2
summary_smote1$bic
## LIMIT_BAL + PAY_1 + +PAY_2 + PAY_3 +PAY_4 +PAY_6

set.seed(123)
logistic_smote2 <- glm(Default ~ LIMIT_BAL+PAY_1+PAY_2+PAY_3+PAY_4+PAY_6, 
                       data = train_df_smote, family = 'binomial')
#summary(logistic_smote2)
## LIMIT_BAL + PAY_1 + PAY_3 + PAY_4 +PAY_5 +PAY_6
logistic_smote2.pred <- predict(logistic_smote2, valid_df,type = 'response')
logistic_smote2.result <- ifelse(logistic_smote2.pred > 0.45, 1, 0)
logistic_smote2.result <- factor(logistic_smote2.result)
confusionMatrix(logistic_smote2.result, as.factor(valid_df$Default),
                positive = "1")

#Decision Tree
set.seed(123)
rpart.credit <- rpart(as.factor(Default)~ ., data =train_df_smote, cp = .01)
rpart.plot(rpart.credit)
#logistic regression with decision tree variables
Model1 <- glm(as.factor(Default) ~ 
PAY_1+PAY_2 + PAY_3 + PAY_4 +BILL_AMT1+ PAY_AMT1+PAY_AMT2, 
data = train_df_smote, family = "binomial")

Model1.pred <- predict(Model1, valid_df, type = "response")
#df <- data.frame(actual = valid_df$Default, prediction = logistic_smote.pred)
Model1.result <- ifelse(Model1.pred > 0.45, 1, 0)
Model1.result <- factor(Model1.result)
confusionMatrix(Model1.result, as.factor(valid_df$Default), positive = "1")

#Random Forest Classifier
set.seed(123)
#random forest on the reduced model 
rnf1 <-  randomForest(as.factor(Default) ~ .,ntree=1000 ,mtry = 5, data = 
                        train_df_smote, cutoff =c(0.55,0.45))
rnf1
rnf1_model.pred <- predict(rnf1, valid_df)
confusionMatrix(rnf1_model.pred, as.factor(valid_df$Default), positive="1")

#Boosting Classifier
set.seed(123)
train_df_smote$Default <- factor(train_df_smote$Default)
boost <- boosting(Default~ .,data = train_df_smote)
pred <- predict(boost, valid_df)
boost2 <- ifelse(pred$prob[ , 2] > 0.45, 1, 0)
confusionMatrix(as.factor(boost2), as.factor(valid_df$Default),positive = '1')
```


\newpage
# Sources    

* [https://www.thebalance.com/what-is-credit-card-default](https://www.thebalance.com/what-is-credit-card-default-960209#:~:text=If%20you%20miss%20the%20minimum,default%20to%20the%20credit%20bureaus)   

* [https://www.valuepenguin.com/what-happens-if-you-dont-pay-credit-card-bill](https://www.valuepenguin.com/what-happens-if-you-dont-pay-credit-card-bill#:~:text=If%20you%20don't%20pay%20your%20credit%20card%20bill%2C%20expect,and%20have%20your%20wages%20garnished)    

* [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)   

* [https://cran.r-project.org/web/packages/adabag/adabag.pdf](https://cran.r-project.org/web/packages/adabag/adabag.pdf)    

* [https://cran.r-project.org/web/packages/randomForest/randomForest.pdf](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)   

* [https://ggplot2-book.org/index.html](https://ggplot2-book.org/index.html)   

* [https://r4ds.had.co.nz/data-visualisation.html](https://r4ds.had.co.nz/data-visualisation.html) 

* [https://www.datatechnotes.com/2018/03/classification-with-adaboost-model-in-r](https://www.datatechnotes.com/2018/03/classification-with-adaboost-model-in-r.html#:~:text=AdaBoost%20(Adaptive%20Boosting)%20is%20a%20boosting%20algorithm%20in%20machine%20learning.&text=Adaboost%20improves%20those%20classifiers%20by,to%20classify%20data%20in%20R)

* [Galit Shmueli, Peter Bruce, Inbal Yahav, Nitin Patel, and Kenneth Lichtendahl. Data Mining for Business Analytics: Concepts, Techniques, and Applications in R, 1st edition, 2018. Wiley. ISBN: 978-1-118-87936-8 (Hardcover), ISBN: 978-1-118-87933-7]   




